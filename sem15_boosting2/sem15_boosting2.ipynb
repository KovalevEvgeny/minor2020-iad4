{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Современные библиотеки градиентного бустинга\n",
    "\n",
    "Ранее мы использовали наивную версию градиентного бустинга из scikit-learn, [придуманную](https://projecteuclid.org/download/pdf_1/euclid.aos/1013203451) в 1999 году Фридманом. С тех пор было предложено много реализаций, которые оказываются лучше на практике. На сегодняшний день популярны три библиотеки, реализующие градиентный бустинг:\n",
    "* XGBoost. После выхода быстро набрала популярность и оставалась стандартом до конца 2016 года. Одними из основных особенностей имплементации были оптимизированность построения деревьев, а также различные регуляризации модели.\n",
    "* LightGBM. Отличительной чертой является быстрота построения композиции. Например, используется следующий трюк для ускорения обучения: при построении вершины дерева вместо перебора по всем значениям признака производится перебор значений гистограммы этого признака. Таким образом, вместо $O(\\ell)$ требуется $O(\\text{#bins})$. Кроме того, в отличие от других библиотек, которые строят дерево по уровням, LightGBM использует стратегию best-first, т.е. на каждом шаге строит вершину, дающую наибольшее уменьшение функционала. Таким образом, каждое дерево является цепочкой с прикрепленными листьями.\n",
    "* CatBoost. Библиотека от компании Яндекс. Позволяет автоматически обрабатывать категориальные признаки (даже если их значения представлены в виде строк). Кроме того, алгоритм является менее чувствительным к выбору конкретных гиперпараметров. За счёт этого уменьшается время, которое тратит человек на подбор оптимальных гиперпараметров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Основные параметры\n",
    "\n",
    "(lightgbm/catboost)\n",
    "\n",
    "* objective – функционал, на который будет настраиваться композиция\n",
    "* eta / learning_rate – темп (скорость) обучения\n",
    "* num_iterations / n_estimators  – число итераций бустинга\n",
    "\n",
    "#### Параметры, отвечающие за сложность деревьев\n",
    "* max_depth – максимальная глубина \n",
    "* max_leaves / num_leaves – максимальное число вершин в дереве\n",
    "* gamma / min_gain_to_split – порог на уменьшение функции ошибки при расщеплении в дереве\n",
    "* min_data_in_leaf – минимальное число объектов в листе\n",
    "* min_sum_hessian_in_leaf – минимальная сумма весов объектов в листе, минимальное число объектов, при котором делается расщепление \n",
    "* lambda – коэффициент регуляризации (L2)\n",
    "* subsample / bagging_fraction – какую часть объектов обучения использовать для построения одного дерева \n",
    "* colsample_bytree / feature_fraction – какую часть признаков использовать для построения одного дерева \n",
    "\n",
    "Подбор всех этих параметров — настоящее искусство. Но начать их настройку можно с самых главных параметров: learning_rate и n_estimators. Обычно один из них фиксируют, а оставшийся из этих двух параметров подбирают (например, фиксируют n_estimators=1000 и подбирают learning_rate). Следующим по важности является max_depth. В силу того, что мы заинтересованы в неглубоких деревьях, обычно его перебирают из диапазона [3; 7].\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install catboost\n",
    "!pip install lightgbm\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "def plot_surface(X, y, clf):\n",
    "    h = 0.2\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "\n",
    "X, y = make_classification(n_samples=500, n_features=2, n_informative=2,\n",
    "                           n_redundant=0, n_repeated=0,\n",
    "                           n_classes=2, n_clusters_per_class=2,\n",
    "                           flip_y=0.05, class_sep=0.8, random_state=241)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=241)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier \n",
    "\n",
    "clf = CatBoostClassifier(iterations=300, logging_level='Silent')\n",
    "clf.fit(X_train, y_train)\n",
    "plot_surface(X_test, y_test, clf)\n",
    "\n",
    "print(roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees = [1, 5, 10, 100, 200, 300, 400, 500, 600, 700]\n",
    "quals_train = []\n",
    "quals_test = []\n",
    "for n in n_trees:\n",
    "    clf = CatBoostClassifier(iterations=n, logging_level='Silent')\n",
    "    clf.fit(X_train, y_train)\n",
    "    q_train = roc_auc_score(y_train, clf.predict_proba(X_train)[:, 1])\n",
    "    q_test = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "    quals_train.append(q_train)\n",
    "    quals_test.append(q_test)\n",
    "    \n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(n_trees, quals_train, marker='.', label='train')\n",
    "plt.plot(n_trees, quals_test, marker='.', label='test')\n",
    "plt.xlabel('Number of trees')\n",
    "plt.ylabel('AUC-ROC')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "clf = LGBMClassifier(n_estimators=300)\n",
    "clf.fit(X_train, y_train)\n",
    "plot_surface(X_test, y_test, clf)\n",
    "\n",
    "print(roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees = [1, 5, 10, 100, 200, 300, 400, 500, 600, 700]\n",
    "quals_train = []\n",
    "quals_test = []\n",
    "for n in n_trees:\n",
    "    clf = LGBMClassifier(n_estimators=n)\n",
    "    clf.fit(X_train, y_train)\n",
    "    q_train = roc_auc_score(y_train, clf.predict_proba(X_train)[:, 1])\n",
    "    q_test = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "    quals_train.append(q_train)\n",
    "    quals_test.append(q_test)\n",
    "    \n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(n_trees, quals_train, marker='.', label='train')\n",
    "plt.plot(n_trees, quals_test, marker='.', label='test')\n",
    "plt.xlabel('Number of trees')\n",
    "plt.ylabel('AUC-ROC')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем взять фиксированное количество деревьев, но будем менять их глубину."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = list(range(1, 30, 3))\n",
    "n_trees = 300\n",
    "quals_train = []\n",
    "quals_test = []\n",
    "for d in depth:\n",
    "    lgb = LGBMClassifier(n_estimators=n_trees, max_depth=d)\n",
    "    lgb.fit(X_train, y_train)\n",
    "    q_train = roc_auc_score(y_train, lgb.predict_proba(X_train)[:, 1])\n",
    "    q_test = roc_auc_score(y_test, lgb.predict_proba(X_test)[:, 1])\n",
    "    quals_train.append(q_train)\n",
    "    quals_test.append(q_test)\n",
    "    \n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(depth, quals_train, marker='.', label='train')\n",
    "plt.plot(depth, quals_test, marker='.', label='test')\n",
    "plt.xlabel('Depth of trees')\n",
    "plt.ylabel('AUC-ROC')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И сравним с Catboost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = list(range(1, 12, 2))\n",
    "n_trees = 300\n",
    "quals_train = []\n",
    "quals_test = []\n",
    "for d in depth:\n",
    "    clf = CatBoostClassifier(n_estimators=n_trees, max_depth=d, logging_level=\"Silent\")\n",
    "    clf.fit(X_train, y_train)\n",
    "    q_train = roc_auc_score(y_train, clf.predict_proba(X_train)[:, 1])\n",
    "    q_test = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "    quals_train.append(q_train)\n",
    "    quals_test.append(q_test)\n",
    "    \n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(depth, quals_train, marker='.', label='train')\n",
    "plt.plot(depth, quals_test, marker='.', label='test')\n",
    "plt.xlabel('Depth of trees')\n",
    "plt.ylabel('AUC-ROC')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда у нас получились отличные модели, нужно их сохранить!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.booster_.save_model('lightgbm.txt')\n",
    "\n",
    "clf.save_model('catboost.cbm', format='cbm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И загрузим обратно, когда понадобится их применить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb = LGBMClassifier(model_file='mode.txt')\n",
    "\n",
    "clf = clf.load_model('catboost.cbm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Блендинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Блендинг представляет из себя \"мета-алгоритм\", предсказание которого строится как взвешенная сумма базовых алгоритмов. Рассмотрим простой пример блендинга бустинга и линейной регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "data = load_boston()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    error = (y_true - y_pred) ** 2\n",
    "    return np.sqrt(np.mean(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "cbm = CatBoostRegressor(iterations=100, max_depth=4, learning_rate=0.01, loss_function='RMSE', logging_level='Silent')\n",
    "cbm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cbm = cbm.predict(X_test)\n",
    "y_train_pred_cbm = cbm.predict(X_train)\n",
    "\n",
    "print(\"Train RMSE GB = %.4f\" % rmse(y_train, y_train_pred_cbm))\n",
    "print(\"Test RMSE GB = %.4f\" % rmse(y_test, y_pred_cbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = lr.predict(X_test_scaled)\n",
    "y_train_pred_lr = lr.predict(X_train_scaled)\n",
    "\n",
    "print(\"Train RMSE LR = %.4f\" % rmse(y_train, y_train_pred_lr))\n",
    "print(\"Test RMSE LR = %.4f\" % rmse(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для простоты будем считать, что новый алгоритм $a(x)$ представим как\n",
    "$$\n",
    "    a(x)\n",
    "    =\n",
    "    \\sum_{n = 1}^{N}\n",
    "    w_n b_n(x),\n",
    "$$\n",
    "где $\\sum\\limits_{n=1}^N w_n =1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_weights(y_true, y_pred_1, y_pred_2):\n",
    "    grid = np.linspace(0, 1, 1000)\n",
    "    metric = []\n",
    "    for w_0 in grid:\n",
    "        w_1 = 1 - w_0\n",
    "        y_a = w_0 * y_pred_1 + w_1 * y_pred_2\n",
    "        metric.append([rmse(y_true, y_a), w_0, w_1])\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_blending_train, w_0, w_1 = min(select_weights(y_train, y_train_pred_cbm, y_train_pred_lr), key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_blending_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse(y_test, y_pred_cbm * w_0 +  y_pred_lr * w_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "def stack_models(model, y_true, y_pred_1, y_pred_2):\n",
    "    sample = pd.DataFrame([y_pred_1, y_pred_2]).T\n",
    "    model.fit(sample, y_true)\n",
    "    return model\n",
    "\n",
    "lgb = LGBMRegressor(n_estimators=200, max_depth=3)\n",
    "lgb = stack_models(lgb, y_train, y_train_pred_cbm, y_train_pred_lr)\n",
    "rmse(y_test, lgb.predict(pd.DataFrame([y_pred_cbm, y_pred_lr]).T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге получаем качество на тестовой выборке лучше, чем у каждого алгоритма в отдельности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полезные ссылки:\n",
    "\n",
    "* [Видео про стекинг](https://www.coursera.org/lecture/competitive-data-science/stacking-Qdtt6)\n",
    "* [Продвинутый вариант стекинга с использованием нейросетей](https://www.coursera.org/learn/competitive-data-science/lecture/s8RLi/stacknet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Важность признаков\n",
    "\n",
    "В курсе мы подробно обсуждаем, как добиваться хорошего качества решения задачи: имея выборку $X, y$, построить алгоритм с наименьшей ошибкой. Однако заказчику часто важно понимать, как работает алгоритм, почему он делает такие предсказания. Обсудим несколько мотиваций.\n",
    "\t\n",
    "#### Доверие алгоритму\n",
    "Например, в банках на основе решений, принятых алгоритмом, выполняются финансовые операции, и менеджер, ответственный за эти операции, будет готов использовать алгоритм, только если он понимает, что его решения обоснованы. По этой причине в банках очень часто используют простые линейные алгоритмы. Другой пример из области медицины: поскольку цена ошибки может быть очень велика, врачи готовы использовать только интерпретируемые алгоритмы.\n",
    "\t\n",
    "#### Отсутствие дискриминации (fairness) \n",
    "Вновь пример с банком: алгоритм кредитного скоринга не должен учитывать расовую принадлежность (racial bias) заемщика или его пол (gender bias). Между тем, такие зависимости часто могут присутствовать в датасете (исторические данные), на котором обучался алгоритм.  Еще один пример: известно, что нейросетевые векторы слов содержат gender bias. Если эти вектора использовались при построении системы поиска по резюме для рекрутера, то, например, по запросу `technical skill` он может видеть женские резюме в конце ранжированного списка.\n",
    "\t\n",
    "#### Учет контекста\n",
    "Данные, на которых обучается алгоритм, не отображают всю предметную область. Интерпретация алгоритма позволит оценить, насколько найденные зависимости связаны с реальной жизнью. Если предсказания интерпретируемы, это также говорит о высокой обобщающей способности алгоритма. \n",
    "\n",
    "Теперь обсудим несколько вариантов, как можно оценивать важность признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Веса линейной модели\n",
    "\n",
    "Самый простой способ, который уже был рассмотрен на семинаре про линейные модели: после построения модели каждому признаку будет соответствовать свой вес - если признаки масштабированы, то чем он больше по модулю, тем важнее признак, а знак будет говорить о положительном или отрицательном влиянии на величину целевой переменной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FSTR (Feature strength)\n",
    "\n",
    "[Fstr](https://catboost.ai/docs/concepts/fstr.html) говорит, что важность признака &mdash; это то, насколько в среднем меняется ответ модели при изменении значения данного признака (изменении значения разбиения).\n",
    "\n",
    "Рассчитать его можно так:\n",
    "\n",
    "$$feature\\_importance_{F} = \\sum_{tree, leaves_F} (v_1 - avr)^2\\cdot c_1 +(v_2 - avr)^2\\cdot c_2 = \\left(v_1 - v_2\\right)^2\\frac{c_1c_2}{c_1 + c_2}\\\\\n",
    "\\qquad avr = \\frac{v_1 \\cdot c_1 + v_2 \\cdot c_2}{c_1 + c_2}.$$\n",
    "\n",
    "Мы сравниваем листы, отличающиеся значением сплита в узле на пути к ним: если условие сплита выполняется, объект попадает в левое поддерево, иначе &mdash; в правое. \n",
    "\n",
    "$c_1, c_2 - $  число объектов обучающего датасета, попавших в левое и правое поддерево соответственно, либо суммарный вес этих объектов, если используются веса; $v1, v2 -$значение модели в левом и правом поддереве (например, среднее)\n",
    "\n",
    "\n",
    "Далее значения $feature\\_importance$ нормируются, и получаются величины, которые суммируются в 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val, name in sorted(zip(cbm.feature_importances_, data.feature_names))[::-1]:\n",
    "    print(name, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(cbm.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out-of-bag\n",
    "\n",
    "В случайном лесе за счет обучения на подвыборках можно использовать out-of-bag оценки - ошибка композиции $a(x) = \\sum_{n=1}^N b_n(x)$, построенной с помощью бэггинга с базовыми алгоритмами $b_i(x)$, вычисляется по формуле (подробнее см. конспект лекции 8):\n",
    "     $$\n",
    "     \\text{OOB} = \\sum_{i=1}^\\ell L\\biggl(y_i, \\frac 1 {\\sum_{n=1}^N [x_i \\notin X_n]} \\sum_{n=1}^N [x_i \\notin X_n] b_n(x_i)\\biggr)\n",
    "      $$     \n",
    "Можно показать, что по мере увеличения числа деревьев \n",
    "данная оценка стремится к leave-one-out-оценке,\n",
    "но при этом существенно проще для вычисления.\n",
    "     \n",
    "Итоговый алгоритм подсчета важностей для случайного леса выглядит так:\n",
    "* Вычислить OOB для случайного леса, обученного по исходной обучающей выборке\n",
    "*  Для каждого признака $j$:\n",
    "\n",
    "    * Перемешать значения признака по всем объектам обучающей выборки &mdash; мы хотим сделать признак неинформативным\n",
    "    * Вычислить OOB$_j$ случайного леса, обученного по измененной обучающей выборке\n",
    "    * Оценить важности: $R_j = \\max(0, \\text{OOB}-\\text{OOB}_j)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведем простейший пример, как можно получить такую оценку в sklearn-реализации RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "clf = RandomForestRegressor(n_estimators=100, oob_score=True)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Интерпретация алгоритмов\n",
    "\n",
    "Отдельным направлением исследований является анализ уже построенных алгоритмов. Разберем популярный метод &mdash; [LIME](https://christophm.github.io/interpretable-ml-book/lime.html). \n",
    "   \n",
    "   Предположим, что мы обучили алгоритм $a$ на выборке {$X, y$}, и хотим интерпретировать его предсказания. Алгоритм LIME выполняет локальную интерпретацию, то есть объясняет предсказания для конкретного объекта. Основная идея состоит в локальном приближении разделяющей поверхности алгоритма другим, более простым алгоритмом $b$ (например, линейным). Итак, чтобы объяснить предсказания $a(x)$ на конкретном объекте $x$:\n",
    "   \n",
    "* Сгенерировать выборку точек $x_1, \\dots, x_m$ около объекта $x$.\n",
    "* Обучить интерпретируемый алгоритм $b$ на выборке $\\{(x_1, a(x_1)), \\dots, (x_m, a(x_m))\\}$.\n",
    "* Интерпретировать алгоритм $b$.\n",
    "\n",
    "   Если мы приближаем разделяющую поверхность линейной функцией $b$, то по обученным весам можно сказать, какой вклад вносит каждый признак в предсказания в окрестности точки $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import metrics   #Additional sklearn functions\n",
    "from sklearn.model_selection import learning_curve, GridSearchCV  #Perforing grid search\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "from sklearn.datasets import load_breast_cancer, fetch_lfw_pairs, make_classification\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = titanic[['Pclass', 'Age', 'SibSp', 'Fare']]\n",
    "y = titanic.Survived.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, y, X_test=None, y_test=None, test=True, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain, label=y)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds, verbose_eval=False)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain, y, eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain)\n",
    "    dtrain_predprob = alg.predict_proba(dtrain)[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print (\"\\nModel Report\")\n",
    "    print (\"Accuracy (Train): %.4g\" % metrics.accuracy_score(y, dtrain_predictions))\n",
    "    print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(y, dtrain_predprob))\n",
    "    if test:\n",
    "        dtest_predictions = alg.predict(X_test)\n",
    "        dtest_predprob = alg.predict_proba(X_test)[:,1]\n",
    "        print (\"Accuracy (Test): %.4g\" % metrics.accuracy_score(y_test, dtest_predictions))\n",
    "        print (\"AUC Score (Test): %f\" % metrics.roc_auc_score(y_test, dtest_predprob))\n",
    "    # return alg              \n",
    "    feat_imp = pd.Series(alg.get_booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "# predictors = [x for x in X.columns]\n",
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " booster='gbtree',\n",
    " seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfit(xgb1, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(X_train, y_train)\n",
    "gsearch1.cv_results_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test2 = {\n",
    " 'max_depth':[8,9,10],\n",
    " 'min_child_weight':[4, 5, 6]\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(X_train, y_train)\n",
    "gsearch2.cv_results_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test3 = {\n",
    " 'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=9,\n",
    " min_child_weight=6, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch3.fit(X_train, y_train)\n",
    "gsearch3.cv_results_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb2 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=9,\n",
    " min_child_weight=6,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " booster='gbtree',\n",
    " seed=27)\n",
    "modelfit(xgb2, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test4 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=9,\n",
    " min_child_weight=6, gamma=0., subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch4.fit(X_train, y_train)\n",
    "gsearch4.cv_results_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test5 = {\n",
    " 'subsample':[i/100.0 for i in range(55, 70, 5)],\n",
    " 'colsample_bytree':[i/100.0 for i in range(55, 70,5)]\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=9,\n",
    " min_child_weight=6, gamma=0., subsample=0.6, colsample_bytree=0.6,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test5, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch5.fit(X_train, y_train)\n",
    "gsearch5.cv_results_, gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test6 = {\n",
    " 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=9,\n",
    " min_child_weight=6, gamma=0., subsample=0.6, colsample_bytree=0.55,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test6, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch6.fit(X_train, y_train)\n",
    "gsearch6.cv_results_, gsearch6.best_params_, gsearch6.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb3 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=9,\n",
    " min_child_weight=6,\n",
    " gamma=0,\n",
    " subsample=0.6,\n",
    " colsample_bytree=0.55,\n",
    " reg_alpha = 1e-05,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb3, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb3 = XGBClassifier(\n",
    " learning_rate =0.01,\n",
    " n_estimators=5000,\n",
    " max_depth=9,\n",
    " min_child_weight=6,\n",
    " gamma=0,\n",
    " subsample=0.6,\n",
    " colsample_bytree=0.55,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb3, X_train, y_train, X_test, y_test, early_stopping_rounds=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/9004172/precision-recall-for-multiclass-multilabel-classification\n",
    "# https://towardsdatascience.com/journey-to-the-center-of-multi-label-classification-384c40229bff\n",
    "# https://scikit-learn.org/stable/modules/multiclass.html\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#multiclass-and-multilabel-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([0, 1, 2, 0, 1, 2, 2, 2, 3])\n",
    "y_pred = np.array([0, 2, 1, 0, 0, 1, 3, 3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# micro \n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "\n",
    "for i in range(4):\n",
    "    TP += ((y_true == i) * (y_pred == i)).sum()\n",
    "    FP += ((y_true != i) * (y_pred == i)).sum()\n",
    "    TN += ((y_true != i) * (y_pred != i)).sum()\n",
    "    FN += ((y_true == i) * (y_pred != i)).sum()\n",
    "\n",
    "micro_P, micro_R = TP/(TP+FP), TP/(TP+FN)\n",
    "micro_P, micro_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# macro \n",
    "macro_P, macro_R = 0, 0\n",
    "\n",
    "for i in range(4):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    \n",
    "    TP += ((y_true == i) * (y_pred == i)).sum()\n",
    "    FP += ((y_true != i) * (y_pred == i)).sum()\n",
    "    TN += ((y_true != i) * (y_pred != i)).sum()\n",
    "    FN += ((y_true == i) * (y_pred != i)).sum()\n",
    "\n",
    "    macro_P += TP/(TP+FP)\n",
    "    macro_R += TP/(TP+FN)\n",
    "    \n",
    "macro_P /= 4\n",
    "macro_R /= 4\n",
    "\n",
    "macro_P, macro_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.precision_score(y_true, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.recall_score(y_true, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.precision_score(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.recall_score(y_true, y_pred, average='macro')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
